{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "I think deep learning will continue to be used in the future. The science\n",
    "behind deep learning might not be as much a breakthrough as the the\n",
    "availability of data today. Before the availability of big data, deep networks\n",
    "might not have been very useful because there was not a lot of data to give\n",
    "them to learn. \n",
    "\n",
    "Since the introduction of big data and mass data collection, deep neural\n",
    "networks have reached their potential and are being used for many tasks and\n",
    "their success will mean that they will continue to be used. Tasks like\n",
    "handwriting recognition, translations, and image classfication are used\n",
    "extensively and were made possible and efficient through deep networks.  The\n",
    "other systems like perceptrons and expert systems have not had as much an\n",
    "impact as deep networks and their models have had.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/james/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fashion_mnist dataset\n",
    "from keras.datasets import fashion_mnist \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "num_val_samples = len(train_images)//4\n",
    "for i in range(4):\n",
    "    validation_images = train_images[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    validation_labels = train_labels[i * num_val_samples: (i + 1) * num_val_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/james/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 292us/step - loss: 0.6213 - acc: 0.7690 - val_loss: 0.4757 - val_acc: 0.8335\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.3644 - acc: 0.8663 - val_loss: 0.3108 - val_acc: 0.8873\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.3052 - acc: 0.8887 - val_loss: 0.2714 - val_acc: 0.9029\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.2715 - acc: 0.8997 - val_loss: 0.3133 - val_acc: 0.8783\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.2467 - acc: 0.9090 - val_loss: 0.2198 - val_acc: 0.9198\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.2250 - acc: 0.9177 - val_loss: 0.2204 - val_acc: 0.9205\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.2093 - acc: 0.9235 - val_loss: 0.1865 - val_acc: 0.9321\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.1937 - acc: 0.9283 - val_loss: 0.2326 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.1781 - acc: 0.9341 - val_loss: 0.1495 - val_acc: 0.9457\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.1678 - acc: 0.9386 - val_loss: 0.1422 - val_acc: 0.9481\n",
      "10000/10000 [==============================] - 1s 104us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2562185704946518, 0.9104]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training and evaluation\n",
    "model.compile(optimizer='rmsprop', \n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, \n",
    "          validation_data=(validation_images, validation_labels), epochs=10, batch_size=128)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 15000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.1554 - acc: 0.9427 - val_loss: 0.1392 - val_acc: 0.9502\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.1433 - acc: 0.9465 - val_loss: 0.1290 - val_acc: 0.9529\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.1343 - acc: 0.9506 - val_loss: 0.1438 - val_acc: 0.9447\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.1236 - acc: 0.9543 - val_loss: 0.1176 - val_acc: 0.9591\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.1155 - acc: 0.9569 - val_loss: 0.0966 - val_acc: 0.9661\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.1054 - acc: 0.9615 - val_loss: 0.0867 - val_acc: 0.9713\n",
      "10000/10000 [==============================] - 1s 101us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2937391574323177, 0.9111]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, \n",
    "          validation_data=(validation_images, validation_labels), epochs=6, batch_size=128)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
