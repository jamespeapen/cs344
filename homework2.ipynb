{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I make a list of all mail documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mail corpus                                                                                                                                                                                \n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]                                                                                        \n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]                                                                                                               \n",
    "all_mail = spam_corpus + ham_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make lists of spam and ham words and get the lengths of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mail docs\n",
    "spam = []\n",
    "for mail in spam_corpus:\n",
    "    [spam.append(word.lower()) for word in mail]\n",
    "\n",
    "ham = []\n",
    "for mail in ham_corpus:\n",
    "    [ham.append(word.lower()) for word in mail]\n",
    "    \n",
    "# corpus lengths\n",
    "n_good = len(ham_corpus)\n",
    "n_bad = len(spam_corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list of all documents and the spam and ham lists, I created a hashtable of words and their frequencies in both the spam corpus and the ham corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtable of good and bad words and their frequencies\n",
    "good_words_freqs = {}\n",
    "bad_words_freqs = {}\n",
    "\n",
    "# count each word and its frequency for each spam and ham\n",
    "for mail in all_mail:\n",
    "    [bad_words_freqs.update({word.lower(): spam.count(word.lower())}) for word in mail]\n",
    "\n",
    "for mail in all_mail:\n",
    "    [good_words_freqs.update({word.lower(): ham.count(word.lower())}) for word in mail]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function implements Paul Graham's probability calculation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_calc(word):\n",
    "    '''\n",
    "    Calculate spam probability for each token\n",
    "    '''\n",
    "    g = 2 * good_words_freqs[word] # double the count of ham words to reduce false positives\n",
    "    b = bad_words_freqs[word]\n",
    "    if g + b > 5:\n",
    "        return max(0.01, min(0.99, min(1.0, b/n_bad) / min(1.0, g/n_good) + min(1.0, b/n_bad)))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this algorithm, probabilities are assigned to each word in both corpora. If a word occurs only in the ham corpus, it is assigned a probability of 0.01. If it is found only in the spam corpus, it gets a probability of 0.9. If found in both, Graham's algorithm is used to find a probability. If it is not in either corpus, it is assigned a probability of 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of spam hashtable for each word \n",
    "all_word_probs = {}\n",
    "\n",
    "for mail in all_mail:\n",
    "    for word in mail:\n",
    "        if word not in ham:\n",
    "            all_word_probs[word] = 0.9\n",
    "        elif word not in spam:\n",
    "            all_word_probs[word] = 0.1\n",
    "        elif word in spam and word in ham:\n",
    "            p = probability_calc(word)\n",
    "            all_word_probs[word] = p\n",
    "\n",
    "        elif word not in spam and word not in ham:\n",
    "            all_word_probs[word] = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scoring function finds the probability that a document is spam by finding the product of the probabilities of its words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(mail, probabilities):\n",
    "    prob = 1\n",
    "    for word in mail:\n",
    "        prob*=all_word_probs[word.lower()]\n",
    "    return prob/(prob + (1-prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham: \n",
      "['do', 'i', 'like', 'green', 'eggs', 'and', 'ham']   0.0\n",
      "['i', 'do']   0.0\n",
      "Spam: \n",
      "['I', 'am', 'spam', 'spam', 'I', 'am']   0.6430436100000001\n",
      "['I', 'do', 'not', 'like', 'that', 'spamiam']   0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ham: \")\n",
    "[print(mail, \" \", score(mail, all_word_probs)) for mail in ham_corpus]\n",
    "\n",
    "print(\"Spam: \")\n",
    "[print(mail, \" \", score(mail, all_word_probs)) for mail in spam_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                                                                                                      \n",
    "sys.path.append('/home/james/Documents/Calvin/CS-344/cs344-code/tools/aima')                                    \n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask, rejection_sampling, likelihood_weighting                                                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cloudy)\n",
      "False: 0.5, True: 0.5\n",
      "P(Sprinker | cloudy\n",
      "False: 0.9, True: 0.1\n",
      "P(Cloudy| the sprinkler is running and it’s not raining)\n",
      "False: 0.8, True: 0.2\n",
      "P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
      "False: 0.091, True: 0.909\n",
      "P(Cloudy | the grass is not wet)\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "# Utility variables                                                                                                                                                                          \n",
    "T, F = True, False                                                                                                                                                                           \n",
    "\n",
    "wet_lawns = BayesNet([                                                                                                                                                                       \n",
    "  ('Cloudy', '', 0.5),                                                                                                                                                                     \n",
    "  ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),                                                                                                                                               \n",
    "  ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),                                                                                                                                                    \n",
    "  ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.9, (F, F): 0.0})                                                                                                   \n",
    "  ])                                                                                                                                                                                       \n",
    "\n",
    "#d.                                                                                                                                                                                         \n",
    "print('P(Cloudy)')                                                                                                                                                                           \n",
    "# P(Cloudy) = 0.5 from the network\n",
    "print(enumeration_ask('Cloudy', dict(),  wet_lawns).show_approx())                                                                                                                           \n",
    "\n",
    "\n",
    "print('P(Sprinker | cloudy')                                                                                                                                                                 \n",
    "# P(Sprinkler | Cloudy) = 0.5\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), wet_lawns).show_approx())                                                                                                                  \n",
    "\n",
    "print('P(Cloudy| the sprinkler is running and it’s not raining)')                                                                                                                            \n",
    "print(enumeration_ask('Cloudy', dict(Sprinker=T, Rain=F), wet_lawns).show_approx())                                                                                                          \n",
    "\n",
    "print('P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)')                                                                                                                \n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), wet_lawns).show_approx())                                                                                              \n",
    "\n",
    "print('P(Cloudy | the grass is not wet)')                                                                                                                                                    \n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), wet_lawns).show_approx()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b.                                                                                                                       \n",
    "A full join probability distribution would have 2*2*4 = 16 values                                                                                                                            \n",
    "### 2. c.                                                                                                                                                                                    \n",
    "The Bayes Network for this domain has 9 independent values with the conditional independence relations   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitb1433e61ec2d44ba80c018d2878a6c3e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
