{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I make a list of all mail documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mail corpus                                                                                                                                                                                \n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]                                                                                        \n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]       \n",
    "\n",
    "all_words = []\n",
    "\n",
    "def all_counts(corpus, list):\n",
    "    for mail in corpus:\n",
    "        for word in mail:\n",
    "            if word.lower() not in all_words:\n",
    "                all_words.append(word.lower())\n",
    "            list.append(word.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make lists of spam and ham words and get the lengths of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'spam', 'do', 'not', 'like', 'that', 'spamiam', 'green', 'eggs', 'and', 'ham']\n",
      "['i', 'am', 'spam', 'spam', 'i', 'am', 'i', 'do', 'not', 'like', 'that', 'spamiam']\n"
     ]
    }
   ],
   "source": [
    "# mail docs\n",
    "spam = []\n",
    "ham = []\n",
    "all_counts(spam_corpus, spam)\n",
    "all_counts(ham_corpus, ham)    \n",
    "\n",
    "print(all_words)\n",
    "print(spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list of all documents and the spam and ham lists, I created a hashtable of words and their frequencies in both the spam corpus and the ham corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count each word and its frequency for each spam and ham\n",
    "def counter(list):\n",
    "    dict = {}\n",
    "    for word in all_words:\n",
    "        if list.count(word) == 0:\n",
    "            dict[word] = 1\n",
    "        else:\n",
    "            dict[word] = list.count(word)\n",
    "    return dict\n",
    "\n",
    "# hashtable of good and bad words and their frequencies\n",
    "good_words_freqs = counter(ham)\n",
    "bad_words_freqs = counter(spam)\n",
    "\n",
    "\n",
    "\n",
    "n_good = sum(good_words_freqs.values())\n",
    "n_bad = sum(bad_words_freqs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function implements Paul Graham's probability calculation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_calc(word):\n",
    "    '''\n",
    "    Calculate spam probability for each token\n",
    "    '''\n",
    "    g = 2 * good_words_freqs[word] # double the count of ham words to reduce false positives\n",
    "    b = bad_words_freqs[word]\n",
    "    if g + b > 1:\n",
    "        return max(0.01, min(0.99, min(1.0, b/n_bad) / min(1.0, g/n_good) + min(1.0, b/n_bad)))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this algorithm, probabilities are assigned to each word in both corpora. If a word occurs only in the ham corpus, it is assigned a probability of 0.01. If it is found only in the spam corpus, it gets a probability of 0.9. If found in both, Graham's algorithm is used to find a probability. If it is not in either corpus, it is assigned a probability of 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 0.84375, 'am': 0.9, 'spam': 0.9, 'do': 0.28125, 'not': 0.9, 'like': 0.5, 'that': 0.9, 'spamiam': 0.9, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Probability of spam hashtable for each word \n",
    "all_word_probs = {}\n",
    "\n",
    "for word in all_words:\n",
    "        p = probability_calc(word)\n",
    "        if word not in ham and word not in spam:\n",
    "            all_word_probs[word] = 0.4\n",
    "        elif word not in spam and word in ham:\n",
    "            all_word_probs[word] = 0.01\n",
    "        elif word in spam and word not in ham:\n",
    "            all_word_probs[word] = 0.9\n",
    "        elif word in spam and word in ham:\n",
    "            all_word_probs[word] = p\n",
    "\n",
    "print(all_word_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scoring function finds the probability that a document is spam by finding the product of the probabilities of its words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(mail, probabilities):\n",
    "    prob = 1\n",
    "    for word in mail:\n",
    "        print(\"\\t\", word, \":\\t \", all_word_probs[word.lower()])\n",
    "        prob*=all_word_probs[word.lower()]\n",
    "    print(prob)\n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham: \n",
      "\t do :\t  0.28125\n",
      "\t i :\t  0.84375\n",
      "\t like :\t  0.5\n",
      "\t green :\t  0.01\n",
      "\t eggs :\t  0.01\n",
      "\t and :\t  0.01\n",
      "\t ham :\t  0.01\n",
      "1.1865234375000002e-09\n",
      "['do', 'i', 'like', 'green', 'eggs', 'and', 'ham']   1.1865234375000002e-09\n",
      "\t i :\t  0.84375\n",
      "\t do :\t  0.28125\n",
      "0.2373046875\n",
      "['i', 'do']   0.2373046875\n",
      "\n",
      "Spam: \n",
      "\t I :\t  0.84375\n",
      "\t am :\t  0.9\n",
      "\t spam :\t  0.9\n",
      "\t spam :\t  0.9\n",
      "\t I :\t  0.84375\n",
      "\t am :\t  0.9\n",
      "0.46708681640625005\n",
      "['I', 'am', 'spam', 'spam', 'I', 'am']   0.46708681640625005\n",
      "\t I :\t  0.84375\n",
      "\t do :\t  0.28125\n",
      "\t not :\t  0.9\n",
      "\t like :\t  0.5\n",
      "\t that :\t  0.9\n",
      "\t spamiam :\t  0.9\n",
      "0.08649755859375001\n",
      "['I', 'do', 'not', 'like', 'that', 'spamiam']   0.08649755859375001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ham: \")\n",
    "[print(mail, \" \", score(mail, all_word_probs)) for mail in ham_corpus]\n",
    "\n",
    "print()\n",
    "print(\"Spam: \")\n",
    "[print(mail, \" \", score(mail, all_word_probs)) for mail in spam_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called Baysian filtering because it uses Bayes' Rule to calculate the probability that a given word is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                                                                                                      \n",
    "sys.path.append('/home/james/Documents/Calvin/CS-344/cs344-code/tools/aima')                                    \n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask, rejection_sampling, likelihood_weighting                                                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utility variables                                                                                                                                                                          \n",
    "T, F = True, False                                                                                                                                                                           \n",
    "\n",
    "wet_lawns = BayesNet([                                                                                                                                                                       \n",
    "  ('Cloudy', '', 0.5),                                                                                                                                                                     \n",
    "  ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),                                                                                                                                               \n",
    "  ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),                                                                                                                                                    \n",
    "  ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.9, (F, F): 0.0})                                                                                                   \n",
    "  ])                                                                                                                                                                                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b.                                                                                                                       \n",
    "A full join probability distribution would have 2*2*4 = 16 values                                                                                                                            \n",
    "### 2. c.                                                                                                                                                                                    \n",
    "The Bayes Network for this domain has 9 independent values with the conditional independence relations   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cloudy)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'enumeration_ask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-d469a9424be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# P(Cloudy) = 0.5 from the network <0.5, 0.5>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumeration_ask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cloudy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mwet_lawns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enumeration_ask' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#d.                                                                                                                                                                                         \n",
    "print('P(Cloudy)')                                                                                                                                                                           \n",
    "\n",
    "# P(Cloudy) = 0.5 from the network <0.5, 0.5>\n",
    "print(enumeration_ask('Cloudy', dict(),  wet_lawns).show_approx())                                                                                                                           \n",
    "\n",
    "\n",
    "print('P(Sprinker | cloudy')                                                                                                                                                                 \n",
    "\n",
    "# P(Sprinkler | Cloudy) = 0.1, <0.1, 0.9>\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), wet_lawns).show_approx())                                                                                                                  \n",
    "\n",
    "print('P(Cloudy| the sprinkler is running and it’s not raining)')                                                                                                                            \n",
    "\n",
    "# a<0.5*0.1*0.2, 0.5*0.5*0.8>\n",
    "# = 4.76<0.01, 0.2>\n",
    "# = <0.476, 0.952>\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), wet_lawns).show_approx())                                                                                                          \n",
    "\n",
    "print('P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)')                                                                                                                \n",
    "\n",
    "# <0.99, 0.01> from Bayes Net\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), wet_lawns).show_approx())                                                                                              \n",
    "\n",
    "print('P(Cloudy | the grass is not wet)')                                                                                                                                                    \n",
    "\n",
    "# \n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), wet_lawns).show_approx()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitb1433e61ec2d44ba80c018d2878a6c3e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
