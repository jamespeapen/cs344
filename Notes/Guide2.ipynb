{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide 2 - Local Search\n",
    "\n",
    "## GOFAI\n",
    "Seat up a search problem with:\n",
    "- an initial state\n",
    "- a set of actions: ${a_1, a_2, a_n}$\n",
    "- Transition model: Result(action, state) = state\n",
    "- Goal test: Goal (s) -> {T|F}\n",
    "- Path cost: cost(s1, s2) = ?\n",
    "\n",
    "### Tic-Tac-Toe\n",
    "- Initial state: empty board\n",
    "- actions: 0\n",
    "\n",
    "Describe the following (see Section 4.1  \n",
    "Local Search: when we care about the solution and not so much about the path cost to get there. They operate using a single current node and move only to that node's neighbors. Since they don't retain the followed paths, they use very little memory and can find reasonable solutions for large or infintie state spaces.  \n",
    "Local search explores the state space landscape.  \n",
    "\n",
    "- Hill-Climbing Search: a loop that continually moves in the direction of increasing objective value. It is a **greedy local search** because it does not consider the next move and does quite well. However, it can get stuck in a local maxima and stop because it seems like a globally optimal solutions. It can also get lost on a plateau from where there is not higher state.   \n",
    "- Simulated Annealing: In this case, we try to find a globally minimal solution in a gradient descent model. A move is picked at random and accepted if it improves the situation. Else, it accepts the move with a probability less than 1 and the probability decreases to the degree that the move is bad. The probability is lowered with temperature and this reduces the liklihood of allowing bad moves.   \n",
    "- Local Beam Search: This algorithm keeps a number of randomly generated states to choose from. At each step, if any of the successors of the states have the goal, it stops. If there is no goal state, it selects the best of the them and restarts.\n",
    "    \n",
    "What “hills” does hill-climbing search? It searches the objective functions. The hills are peaks of the objective function. \n",
    "\n",
    "Define:\n",
    " - Local Maximum: a peak in objective function that is higher than its surrounding area, but is not the global maxiumum. \n",
    " - Random Restarts: when hill climbing tries repeatedly to search from random initial states until the goal is reached.  \n",
    "\n",
    "Compare and contrast hill-climbing vs. simulated annealing vs. local beam search.\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitb1433e61ec2d44ba80c018d2878a6c3e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
